---
title: "Acquire"
format: html
---
<!--
Good job.

-->

```{r}
#| label: loading packages
#| message: false
library(dplyr) # data manipulation
library(readr) # data import/ export
library(gutenbergr) # Project Gutenberg API
library(skimr) # descriptive statistics
library(knitr) # tables
library(ggplot2) # plotting
```

## Description of data

<!-- Excellent description of the data origin in prose -->

The data I will be using comes from Project Gutenberg, which, according to [Recipe 5](https://qtalr.github.io/qtalrkit/articles/recipe-5.html) is a "volunteer effort to digitize and archive cultural works." Most fo the works in the database are public domain in the US which means they can be freely accessed, used, and shared. I downloaded the package gutenbergr which will allow me to access the metadata for all of the works available in their database.

```{r}
glimpse(gutenberg_metadata)
```

This data shows that there are 72,569 works in Project Gutenberg's database.

#### I am going to save this data as a csv file

```{r}
metadata_df <- gutenberg_metadata

write_csv(metadata_df, "data/original/gutenberg_metadata.csv")
```

When I loaded this lab, the instructions said to open a quarto document under the process directory. This is that document. However, when I went to write my data and save it as a CSV file, I ran into some issues. I wanted to save the file under `data/original` but it keps saving under the process directory and I couldnt figure out why. I think this is because that both `process` and `data` are under the `lab-05` directory together. I didnt know how to make the file save under `lab-05/data/original` so I created a new data folder under the process directory. I was then able to save my CSV file under `lab-05/process/data/original` but since I was already working on a document in the process directory, I just had to write `data/original` in the code. I deleted the data folder under the `lab-05` directory.

<!--

So it is helpful to understand what the working directory is when you run a Quarto document.

When you run your Quarto document in an RStudio project, the folder in which the Quarto document lives is the default working directory for that file. So if you go to save a file in any of the subdirectories (such as `procees/`), you need to make sure that the path to the file starts from the file that you are working on.

For your example here the relevant path would be: `../data/original/gutenberg_metadata.csv`. The `..` tells R to go up one directory from the current working directory and then go into the `data/original` directory.

Now, when you run code blocks interactively in an R session in RStudio, the working directory is the directory in which the RStudio project file is saved. So if you run the code interactively, you will need to adjust the path to the file accordingly. Working interactively is a good way to test code in Quarto documents, but not the best way to test file paths.

This is confusing, I know.

-->


#### I am also interested in the authors, so I will save metadata about the Gutenberg authors

```{r}
glimpse(gutenberg_authors)

authors_df <- gutenberg_authors

write_csv(authors_df, "data/original/gutenberg_authors.csv")
```

#### I will do the same for the subjects of each work

```{r}
glimpse(gutenberg_subjects)

subjects_df <- gutenberg_subjects

write_csv(subjects_df, "data/original/gutenberg_subjects.csv")
```

<!--
Just a note here: You really don't need to save the data as a CSV file as these metadata are available through the gutenbergr package and they are already in your computing environment.

This is not the case for actual works that we download from Project Gutenberg. Those we will need to save as files.

-->

## Deriving data

<!-- Reading data with `readr` always generates messages that usually are best hid in Quarto documents, so I added `message: false` to your code block below. -->

```{r}
#| message: false

metadata_read <- read_csv("data/original/gutenberg_metadata.csv")
write_csv(metadata_read, "data/derived/gutenberg_metadata_read.csv")

authors_read <- read_csv("data/original/gutenberg_authors.csv")
write_csv(authors_read, "data/derived/gutenberg_authors_read.csv")

subjects_read <- read_csv("data/original/gutenberg_subjects.csv")
write_csv(subjects_read, "data/derived/gutenberg_subjects_read.csv")

```

Ok that might have been useless because I'm looking at `authors_df` and `authors_read` and I think they are just the same thing. I think maybe what I was trying to do was summarize the data. I'll try that instead now to display the results.

<!-- Yes, they are the same thing. ;) -->

## Summary of results

<!--
While the `summary()` function can be useful sometimes. A more useful function is the `skim()` function from the `skimr` package. It provides a more detailed summary of the data.

-->

```{r}
# summary(authors_read)
skim(authors_df)
```

```{r}
# summary(metadata_read)
skim(metadata_df)
```

```{r}
# summary(subjects_read)
skim(subjects_df)
```

<!--

Note that you've visualized the metadata, but have not acquired any actual works from Project Gutenberg. To actually get data from project gutenberg, you would need to use the `gutenberg_download()` function from the `gutenbergr` package. With the gutenberg ids that you want to download.

Below I include an example.

-->


The code below checks if the file `twain_books.csv` already exists. If it does not, it downloads works by Mark Twain. The works are selected by filtering the metadata for works by Mark Twain that have text available, selecting the first five works, and downloading them. The works are saved as a CSV file.

```{r}
#| label: acquire-works-twain-example

# Check if `twain_books.csv` already exists

if (fs::file_exists("../data/original/twain_books.csv")) {
  message("File already exists. Skipping download.")
} else {
  message("Downloading works by Mark Twain.")
  # Identify works by Mark Twain
  twain_ids <-
    gutenberg_metadata |>
    filter(author == "Twain, Mark", has_text) |>
    slice_head(n = 5) |>
    pull(gutenberg_id)

  # Preview
  twain_ids

  # Download the works
  twain_books <- gutenberg_download(twain_ids, meta_fields = "title")

  # Preview
  glimpse(twain_books)

  # Save the works
  write_csv(twain_books, "../data/original/twain_books.csv")
}
```

Then we create and edit the data origin file. *Note: this is done manually once, therefore the code bock is set to `eval: false`.*

```{r}
#| label: acquire-works-twain-example-do
#| eval: false

# Create data origin file (and edit)
qtalrkit::create_data_origin(file_path = "../data/original/twain_books_do.csv")
```

We can preview the *data/* directory to see the files that have been created.

```{r}
#| label: preview-data-directory

fs::dir_tree("../data")
```

